
List packages in the venv:
Activate your venv and run:

pip freeze > venv_requirements.txt
List packages in the system-wide Python:
Deactivate the venv and run:

pip freeze > system_requirements.txt
Compare the two files:
You can use a diff tool or simply view both files to identify differences.

Install missing packages in the system-wide Python:

pip install -r venv_requirements.txt

Alignment with Venv:
If there are still discrepancies between your system-wide Python and the venv, you can generate a requirements file from the venv and apply it to the system-wide Python:

bash
pip freeze > requirements.txt
pip install -r requirements.txt

pip list


Stress Testing XPU Performance

import torch
import time

size = 10000  # Increase size

# CPU Test
cpu_tensor = torch.randn(size, size, device="cpu")
start = time.time()
cpu_result = cpu_tensor @ cpu_tensor
print("CPU Time:", time.time() - start)

# XPU Test
if torch.xpu.is_available():
    xpu_tensor = cpu_tensor.to("xpu")
    start = time.time()
    xpu_result = xpu_tensor @ xpu_tensor
    print("XPU Time:", time.time() - start)


-----------------
Results:

>>> import torch
>>> import time
>>> 
>>> size = 10000  # Increase size
>>> 
>>> # CPU Test
>>> cpu_tensor = torch.randn(size, size, device="cpu")
>>> start = time.time()
>>> cpu_result = cpu_tensor @ cpu_tensor
>>> print("CPU Time:", time.time() - start)
CPU Time: 18.95138144493103
>>> 
>>> # XPU Test
>>> if torch.xpu.is_available():
...     xpu_tensor = cpu_tensor.to("xpu")
...     start = time.time()
...     xpu_result = xpu_tensor @ xpu_tensor
...     print("XPU Time:", time.time() - start)
... 
XPU Time: 0.20033788681030273
>>> 


----------------------
find ~/ -type f -name "activate" 2>/dev/null




source /home/andy/stable-diffusion-webui-forge/venv/bin/activate
source /home/andy/stable-diffusion-reforge/venv/bin/activate
source /home/andy/ComfyUI/venv/bin/activate
source /home/andy/stable-diffusion-webui/Automatic1111_env/bin/activate
source /home/andy/Easy-Diffusion-Linux/easy-diffusion/installer_files/env/bin/activate

source /snap/openvino-ai-plugins-gimp/current/bin/activate

(install) andy@ak10pro:~/Documents$ pip freeze > openvino_gimp_requirements.txt
(install) andy@ak10pro:~/Documents$ source /snap/openvino-ai-plugins-gimp/current/bin/activate
(install) andy@ak10pro:~/Documents$ python cpuVsXpu.py 
Torch Version: 2.5.1+cxx11.abi
CPU Time: 0.034555912017822266
XPU Time: 0.11891007423400879
Speedup: 0.29x ðŸš€

---------------------------------------------



(install) andy@ak10pro:~/Documents$ find ~/ -type f -name "activate" 2>/dev/null

/home/andy/.local/share/uv/python/cpython-3.11.11-linux-x86_64-gnu/lib/python3.11/venv/scripts/common/activate
/home/andy/.pyenv/versions/3.9.13/envs/venv-stablediffusion/bin/activate
/home/andy/.pyenv/versions/3.9.13/lib/python3.9/venv/scripts/common/activate
/home/andy/.pyenv/shims/activate
/home/andy/.pyenv/plugins/pyenv-virtualenv/shims/activate

/home/andy/miniconda3/envs/easy_diffusion/lib/python3.10/venv/scripts/common/activate
/home/andy/miniconda3/envs/stable-diffusion-ui-installer/bin/activate
/home/andy/miniconda3/envs/stable-diffusion-ui-installer/lib/python3.12/venv/scripts/common/activate
/home/andy/miniconda3/envs/stable-diffusion-ui-installer/lib/python3.12/site-packages/conda/shell/bin/activate
/home/andy/miniconda3/bin/activate
/home/andy/miniconda3/lib/python3.12/venv/scripts/common/activate
/home/andy/miniconda3/lib/python3.12/site-packages/conda/shell/bin/activate
/home/andy/miniconda3/pkgs/python-3.10.16-he870216_1/lib/python3.10/venv/scripts/common/activate
/home/andy/miniconda3/pkgs/conda-25.1.1-py312h06a4308_0/bin/activate
/home/andy/miniconda3/pkgs/conda-25.1.1-py312h06a4308_0/lib/python3.12/site-packages/conda/shell/bin/activate
/home/andy/miniconda3/pkgs/python-3.12.9-h5148396_0/lib/python3.12/venv/scripts/common/activate

/home/andy/Easy-Diffusion-Linux/easy-diffusion/installer_files/mamba/pkgs/python-3.8.5-h1103e12_9_cpython/lib/python3.8/venv/scripts/common/activate
/home/andy/Easy-Diffusion-Linux/easy-diffusion/installer_files/mamba/pkgs/conda-23.9.0-py38h578d9bd_2/bin/activate
/home/andy/Easy-Diffusion-Linux/easy-diffusion/installer_files/mamba/pkgs/conda-23.9.0-py38h578d9bd_2/lib/python3.8/site-packages/conda/shell/bin/activate
/home/andy/Easy-Diffusion-Linux/easy-diffusion/installer_files/env/bin/Activate
/home/andy/Easy-Diffusion-Linux/easy-diffusion/installer_files/env/lib/python3.8/site-packages/conda/shell/bin/activate
/home/andy/.venv/bin/activate

pip freeze > openvino_gimp_requirements.txt
----------------------------------------------------------------------------------------------
/home/andy/Easy-Diffusion-Linux/easy-diffusion/installer_files/env/lib/python3.8/venv/scripts/common/activate
/home/andy/ComfyUI/venv/bin/activate
/home/andy/stable-diffusion-webui/Automatic1111_env/bin/activate
/home/andy/stable-diffusion-webui-forge/venv/bin/activate
/home/andy/stable-diffusion-reforge/venv/bin/activate
/snap/openvino-ai-plugins-gimp/current/bin/activate

(invoke) andy@ak10pro:~$ source /home/andy/.venv/bin/activate

/home/andy/openvino_env/bin/activate
/home/andy/llm-cpp/bin/activate

System pytorch ok : best-genai-openvino-pytorch-xpu-requirements.txt
openvino pytorch ok: openvino_requirements.txt
easy-diffusion_requirements.txt
comfyui_requirements.txt
Automatic1111_requirements.txt
forge_requirements.txt
reforge_requirements.txt
openvino_gimp_requirements.txt

ipexllm_requirements.txt

------------------------------------------------------------------------------------------------------
deactivate
rm -rf ~/test-env
python3 -m venv ~/test-env
source ~/test-env/bin/activate
pip install --upgrade pip
source /opt/intel/oneapi/setvars.sh
export SYCL_CACHE_PERSISTENT=1
------------------------------------------------------------------------------------------------------
STEP 1:
======
pip install --pre --upgrade ipex-llm[xpu] --extra-index-url https://pytorch-extension.intel.com/release-whl/stable/xpu/us/
    Installing collected packages: tcmlib, sentencepiece, py-cpuinfo, mpmath, ipex-llm, bigdl-core-xe-batch-21, bigdl-core-xe-addons-21, bigdl-core-xe-21, urllib3, umf, typing-extensions, tqdm, tabulate, sympy, safetensors, regex, pyyaml, psutil, protobuf, pillow, packaging, numpy, networkx, MarkupSafe, idna, fsspec, filelock, charset-normalizer, certifi, annotated-types, typing-inspection, requests, pydantic-core, jinja2, intel-cmplr-lib-ur, 
    torch, pydantic, intel-openmp, huggingface-hub, torchvision, tokenizers, intel-extension-for-pytorch, accelerate, transformers


------------------------------------------------------------------------------------------------------
STEP 2:
=======

https://docs.openvino.ai/2025/get-started/install-openvino/install-openvino-pip.html

python -m pip install --pre -U openvino openvino-tokenizers --extra-index-url https://storage.openvinotoolkit.org/simple/wheels/nightly
    Installing collected packages: openvino-telemetry, packaging, numpy, openvino, openvino-tokenizers


Examples:
https://github.com/openvinotoolkit/openvino_notebooks/tree/latest/notebooks/stable-diffusion-v2

......................................................................................................
STEP 3: How to install intel pytorch:
=======
https://pytorch-extension.intel.com/installation?platform=gpu&version=v2.6.10%2Bxpu&os=linux%2Fwsl2&package=pip


python -m pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/xpu
    Installing collected packages: tcmlib, mpmath, intel-pti, intel-cmplr-lic-rt, intel-cmplr-lib-rt, umf, typing-extensions, sympy, pillow, packaging, numpy, networkx, MarkupSafe, fsspec, filelock, pytorch-triton-xpu, jinja2, intel-cmplr-lib-ur, intel-sycl-rt, torch, torchvision, torchaudio


python -m pip install intel-extension-for-pytorch==2.6.10+xpu oneccl_bind_pt==2.6.0+xpu --extra-index-url https://pytorch-extension.intel.com/release-whl/stable/xpu/us/
    Installing collected packages: tcmlib, oneccl_bind_pt, intel-cmplr-lic-rt, intel-cmplr-lib-rt, impi-rt, umf, typing-extensions, tbb, ruamel.yaml.clib, psutil, packaging, numpy, impi-devel, annotated-types, ruamel.yaml, pydantic-core, intel-opencl-rt, intel-cmplr-lib-ur, pydantic, intel-sycl-rt, intel-openmp, oneccl, mkl, dpcpp-cpp-rt, onemkl-sycl-vm, onemkl-sycl-stats, onemkl-sycl-rng, onemkl-sycl-dft, onemkl-sycl-datafitting, onemkl-sycl-blas, oneccl-devel, onemkl-sycl-sparse, onemkl-sycl-lapack, mkl-dpcpp, intel-extension-for-pytorch


(test-env) andy@ak10pro:~$ pip check
No broken requirements found.
(test-env) andy@ak10pro:~$ python -m pip install intel-extension-for-pytorch==2.6.10+xpu oneccl_bind_pt==2.6.0+xpu --extra-index-url https://pytorch-extension.intel.com/release-whl/stable/xpu/us/



pip install --upgrade torchvision
pip install --upgrade torchaudio

pip check
pip list......................................................................................................

pip search torch -i https://download.pytorch.org/whl/xpu


pip install torch==2.0.1 torchvision==0.15.0 --use-deprecated=legacy-resolver


python -c "import torch; print(torch.__version__)"
python -c "import intel_extension_for_pytorch as ipex; print(ipex.__version__)"

/home/andy/ComfyUI/venv/bin/python -m pip install -r /home/andy/ComfyUI/requirements.txt
pip install torch==2.6.0 torchvision==0.21.0+xpu torchaudio==2.6.0 --index-url https://download.pytorch.org/whl/xpu



fooocus_env) andy@ak10pro:~/Fooocus$ pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/xpu
pip install intel_extension_for_pytorch
Looking in indexes: https://download.pytorch.org/whl/xpu
Collecting torch
  Using cached https://download.pytorch.org/whl/xpu/torch-2.6.0%2Bxpu-cp310-cp310-linux_x86_64.whl.metadata (27 kB)
Collecting torchvision
  Using cached https://download.pytorch.org/whl/xpu/torchvision-0.21.0%2Bxpu-cp310-cp310-linux_x86_64.whl.metadata (6.1 kB)
Collecting torchaudio
  Using cached https://download.pytorch.org/whl/xpu/torchaudio-2.6.0%2Bxpu-cp310-cp310-linux_x86_64.whl.metadata (6.6 kB)
Requirement already satisfied: filelock in ./fooocus_env/lib/python3.10/site-packages (from torch) (3.18.0)
Requirement already satisfied: typing-extensions>=4.10.0 in ./fooocus_env/lib/python3.10/site-packages (from torch) (4.12.2)
Requirement already satisfied: sympy==1.13.1 in ./fooocus_env/lib/python3.10/site-packages (from torch) (1.13.1)
Requirement already satisfied: networkx in ./fooocus_env/lib/python3.10/site-packages (from torch) (3.4.2)
Requirement already satisfied: jinja2 in ./fooocus_env/lib/python3.10/site-packages (from torch) (3.1.6)
Requirement already satisfied: fsspec in ./fooocus_env/lib/python3.10/site-packages (from torch) (2025.3.0)
Requirement already satisfied: intel-cmplr-lib-rt==2025.0.2 in ./fooocus_env/lib/python3.10/site-packages (from torch) (2025.0.2)
Requirement already satisfied: intel-cmplr-lib-ur==2025.0.2 in ./fooocus_env/lib/python3.10/site-packages (from torch) (2025.0.2)
Requirement already satisfied: intel-cmplr-lic-rt==2025.0.2 in ./fooocus_env/lib/python3.10/site-packages (from torch) (2025.0.2)
Requirement already satisfied: intel-sycl-rt==2025.0.2 in ./fooocus_env/lib/python3.10/site-packages (from torch) (2025.0.2)
Requirement already satisfied: tcmlib==1.2.0 in ./fooocus_env/lib/python3.10/site-packages (from torch) (1.2.0)
Requirement already satisfied: umf==0.9.1 in ./fooocus_env/lib/python3.10/site-packages (from torch) (0.9.1)
Requirement already satisfied: intel-pti==0.10.0 in ./fooocus_env/lib/python3.10/site-packages (from torch) (0.10.0)
Requirement already satisfied: pytorch-triton-xpu==3.2.0 in ./fooocus_env/lib/python3.10/site-packages (from torch) (3.2.0)
Requirement already satisfied: packaging in ./fooocus_env/lib/python3.10/site-packages (from pytorch-triton-xpu==3.2.0->torch) (24.1)
Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./fooocus_env/lib/python3.10/site-packages (from sympy==1.13.1->torch) (1.3.0)
Requirement already satisfied: numpy in ./fooocus_env/lib/python3.10/site-packages (from torchvision) (1.26.4)
Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in ./fooocus_env/lib/python3.10/site-packages (from torchvision) (10.4.0)
Requirement already satisfied: MarkupSafe>=2.0 in ./fooocus_env/lib/python3.10/site-packages (from jinja2->torch) (2.1.5)
Using cached https://download.pytorch.org/whl/xpu/torch-2.6.0%2Bxpu-cp310-cp310-linux_x86_64.whl (1029.5 MB)
Using cached https://download.pytorch.org/whl/xpu/torchvision-0.21.0%2Bxpu-cp310-cp310-linux_x86_64.whl (1.8 MB)
Using cached https://download.pytorch.org/whl/xpu/torchaudio-2.6.0%2Bxpu-cp310-cp310-linux_x86_64.whl (1.8 MB)
Installing collected packages: torch, torchvision, torchaudio
Successfully installed torch-2.6.0+xpu torchaudio-2.6.0+xpu torchvision-0.21.0+xpu
Collecting intel_extension_for_pytorch
  Using cached intel_extension_for_pytorch-2.6.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (7.4 kB)
Requirement already satisfied: psutil in ./fooocus_env/lib/python3.10/site-packages (from intel_extension_for_pytorch) (6.0.0)
Requirement already satisfied: numpy in ./fooocus_env/lib/python3.10/site-packages (from intel_extension_for_pytorch) (1.26.4)
Requirement already satisfied: packaging in ./fooocus_env/lib/python3.10/site-packages (from intel_extension_for_pytorch) (24.1)
Using cached intel_extension_for_pytorch-2.6.0-cp310-cp310-manylinux_2_28_x86_64.whl (105.4 MB)
Installing collected packages: intel_extension_for_pytorch
Successfully installed intel_extension_for_pytorch-2.6.0
(fooocus_env) andy@ak10pro:~/Fooocus$ python -c "import torch; print(torch.xpu.is_available())"
True

dpkg -l | grep intel

example of how to use -f switch in pip

pip uninstall torch torchvision torchaudio -y # Ensure clean slate
andy@ak10pro:~/OpenVino-CodeSamples$ pip install torch==1.13.1+cpu torchvision==0.14.1+cpu torchaudio==0.13.1+cpu -f https://download.pytorch.org/whl/torch_stable.html


----
ComfyUI upgrade
deactivate
rm -rf venv/
python3 -m venv venv
pip install -r requirements.txt
python main.py --lowvram  
source venv/bin/activate
pip install --upgrade -r requirements.txt
python main.py --lowvram  



pip install --force-reinstall "mkl-dpcpp==2025.0.1"
andy@ak10pro:~/Downloads/squashfs-root$ python -c "import torch;import intel_extension_for_pytorch as ipex;print(ipex.xpu.get_device_name(0))"



----------------------------------------------------------------------------------------------
/home/andy/Easy-Diffusion-Linux/easy-diffusion/installer_files/env/lib/python3.8/venv/scripts/common/activate
/home/andy/ComfyUI/venv/bin/activate
/home/andy/stable-diffusion-webui/Automatic1111_env/bin/activate
/home/andy/stable-diffusion-webui-forge/venv/bin/activate
/home/andy/stable-diffusion-reforge/venv/bin/activate
/snap/openvino-ai-plugins-gimp/current/bin/activate

(invoke) andy@ak10pro:~$ source /home/andy/.venv/bin/activate


https://www.intel.com/content/www/us/en/developer/tools/oneapi/base-toolkit-download.html?packages=oneapi-toolkit&oneapi-toolkit-os=linux&oneapi-lin=apt
pip install mkl mkl-devel mkl-dpcpp onemkl-sycl-blas onemkl-sycl-lapack onemkl-sycl-sparse

pip install --force-reinstall 'https://github.com/bitsandbytes-foundation/bitsandbytes/releases/download/continuous-release_multi-backend-refactor/bitsandbytes-0.44.1.dev0-py3-none-manylinux_2_24_x86_64.whl'






Toi fix error while launcing auto111 with use ipx:


from typing import Union
def is_xpu_device(device: Union[str, torch.device] = None):


Do not add #source /opt/intel/openvino_2025.0.0/setupvars.sh to the bashrc file. It is causing conflicts.

Run the commands
(base) andy@ak10pro:~$ env | grep -i openvino
(base) andy@ak10pro:~$ echo $PYTHONPATH


import torch
print(torch.xpu.memory_summary())
